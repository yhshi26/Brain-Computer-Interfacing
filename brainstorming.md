# Brain-Computer Interface Research Brainstorming
**Objective:** learn about electroencephalography (EEG) and parsing brain-data to produce brain-computer interfaces, starting with smaller projects.

## Small projects
These small projects are listed in order of increasing predicted difficulty.

### Pong
- code simple two-player game, hit ball back and forth
- take brain-data as input
  - parse for up/down

### Human-human interfacing
- take brain-data as input
  - parse(?)
- use motor-control on another subject using electrode on corresponding limb

### Drone
- use pre-built drone from inventory
- control drone movement using brain-data as input
  - parse for up/down, cardinal directions (N,E,S,W)

### Prosthetic arm
- use inventory from previous prosthetic arm project
  - rebuild prosthetic
- control phalange (finger) movement using brain-data as input
  - parse for each of the 5 fingers
  - parse for flexion/extension

### Chess
- use previous chess project (but use a simulated version on a computer first)
- control chess pieces using brain-data as input
  - parse for starting and ending coordinates (easier than parsing for pieces)

### Virtual keyboard
- type something using brain-data as input
  - parse for letters, numbers and punctuation (very difficult)

## Future research
These are some ideas for future research (potentially) possible after familiarizing ourselves with using electrodes for electroencephalography, and parsing different kinds of data from parts of the brain (cortexes):
  - e.g. can we map out/visualize parts of the brain at work when solving easy vs. difficult problems? (e.g. easy vs. difficult math problems)
  - e.g. what parts of the brain are active when people are exposed to new vs. old concepts? (researches learning)
  - e.g. what does the brain look like when people try to multitask? (e.g. count down from 100 in 7s while paying attention to a video with some objective that must be achieved at the end)
- comparing brain activity in different groups of subjects when exposed to some stimuli
  - e.g. is there a measurable difference in brain activity with people who have strong navigational abilities and those who don't? can we map/visualize it?
  - e.g. do deaf people experience reading differently? (some do not experience "internal monologue" with small vibrations in their eardrums, so does a different part of their brain activate to make up for that? the visual cortex?)
  - e.g. do professionals experience their medium (mathematicians:math, artists:art, athlete:sport, etc.) differently from others?
